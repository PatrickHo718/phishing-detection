{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHYcBKL2u0sg"
      },
      "source": [
        "**Logistic regression is applied for classification tasks, using ridge (L2), lasso (L1), and ElasticNet (a mix of L1 and L2) regularization.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I1f3rZU-jY0"
      },
      "source": [
        "\n",
        "- **Ridge Regression (L2 penalty):** Adds a penalty proportional to the square of the magnitude of the coefficients.\n",
        "\n",
        "  $$\n",
        "  R(\\beta_j) = \\sum_{j}\\beta_j^2\n",
        "  $$\n",
        "\n",
        "- **Lasso Regression (L1 penalty):** Adds a penalty proportional to the absolute value of the coefficients, which can drive some coefficients exactly to zero, resulting in sparse models.\n",
        "\n",
        "  $$\n",
        "  R(\\beta_j) = \\sum_{j}|\\beta_j|\n",
        "  $$\n",
        "\n",
        "- **ElasticNet:** Combines both L1 and L2 penalties, controlled by a mixing parameter $\\lambda_{\\text{mixing}}$.\n",
        "\n",
        "  $$\n",
        "  R(\\beta_j) = \\lambda_{\\text{mixing}} \\sum_{j}|\\beta_j| + (1 - \\lambda_{\\text{mixing}}) \\sum_{j}\\beta_j^2\n",
        "  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4IgRoQj591i"
      },
      "source": [
        "### **Importing Necessary Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C3KiEIa9DMgS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pylab as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeCNsSTL6I3i"
      },
      "source": [
        "### **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LNOEYZPfC_2s"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Data/phishing_train.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOo7lvRX6Ogt"
      },
      "source": [
        "### **Splitting Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rw2zoRC0IQWQ"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1uKwuXE6mtZ"
      },
      "source": [
        "### **Ridge Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gApxawFB2wR",
        "outputId": "e1f2af57-3c06-4cc9-b9b8-5b39df9b2a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Ridge Hyperparameters: {'model__C': 0.1}\n",
            "Train Accuracy: 0.9295944519825117\n",
            "Test Accuracy: 0.9294436906377205\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 898   87]\n",
            " [  69 1157]]\n"
          ]
        }
      ],
      "source": [
        "# Creating pipeline to prevent data leakage\n",
        "pipeline_rr = Pipeline([\n",
        "    ('scaler', StandardScaler()), # Scaling Data\n",
        "    ('model', LogisticRegression( # Logistic Regression\n",
        "        penalty='l2',             # Ridge Regression\n",
        "        solver='saga',            # Universal Solver for All 3 Types of Regression\n",
        "        max_iter=5000,            # Maximum number of iterations for solver to converge\n",
        "        random_state=1234         # Random State for Consistency\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Defining Parameters for Cross Validation\n",
        "rr_cv_parameters = {\n",
        "    'model__C': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Performing Cross Validation with GridSearchCV\n",
        "rr = GridSearchCV(\n",
        "    estimator=pipeline_rr,\n",
        "    param_grid=rr_cv_parameters,\n",
        "    cv=5, # 5 folds for CV\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "# Fitting Model\n",
        "rr.fit(X_train, y_train)\n",
        "\n",
        "# Finding the Best Model\n",
        "best_rr = rr.best_estimator_\n",
        "\n",
        "# Predictions with the best performing model\n",
        "pred_train_rr = best_rr.predict(X_train)\n",
        "pred_test_rr = best_rr.predict(X_test)\n",
        "\n",
        "# Performance Metrics\n",
        "print(\"Best Ridge Hyperparameters:\", rr.best_params_)\n",
        "print(\"Train Accuracy:\", accuracy_score(y_train, pred_train_rr))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, pred_test_rr))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, pred_test_rr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HXd_QAP8mlf"
      },
      "source": [
        "### **Lasso Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qfm02KrCQwm",
        "outputId": "59b8c708-bd46-46fd-d57b-6ac6dc643366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Lasso Hyperparameters: {'model__C': 0.1}\n",
            "Train Accuracy: 0.9311020654304236\n",
            "Test Accuracy: 0.9308005427408412\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 895   90]\n",
            " [  63 1163]]\n"
          ]
        }
      ],
      "source": [
        "# Creating pipeline to prevent data leakage\n",
        "pipe_lr = Pipeline([\n",
        "    ('scaler', StandardScaler()), # Scaling Data\n",
        "    ('model', LogisticRegression( # Logistic Regression\n",
        "        penalty='l1',             # Lasso Regression\n",
        "        solver='saga',            # Universal Solver for All 3 Types of Regression\n",
        "        max_iter=5000,            # Maximum number of iterations for solver to converge\n",
        "        random_state=1234         # Random State for Consistency\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Defining Parameters for Cross Validation\n",
        "lr_cv_parameters = {\n",
        "    'model__C': [0.01, 0.1, 1, 10, 100] #C is the inverse regularization strength; smaller = stronger regularization\n",
        "}\n",
        "\n",
        "# Performing Cross Validation with GridSearchCV\n",
        "lr = GridSearchCV(\n",
        "    estimator=pipe_lr,\n",
        "    param_grid=lr_cv_parameters,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fitting the Model\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Finding the Best Model\n",
        "best_lr = lr.best_estimator_\n",
        "\n",
        "# Predictions with the best performing model\n",
        "pred_train_lr = best_lr.predict(X_train)\n",
        "pred_test_lr = best_lr.predict(X_test)\n",
        "\n",
        "# Performance Metrics\n",
        "print(\"Best Lasso Hyperparameters:\", lr.best_params_)\n",
        "print(\"Train Accuracy:\", accuracy_score(y_train, pred_train_lr))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, pred_test_lr))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, pred_test_lr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EK3wVa29oGH"
      },
      "source": [
        "### **Elastic Net Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JChK_o-e-pWp",
        "outputId": "826c8686-26c9-44e0-f798-1608f1c46293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Hyperparameters: {'model__C': 0.1, 'model__l1_ratio': 0.7}\n",
            "Train Accuracy: 0.9301974973616765\n",
            "Test Accuracy: 0.9298959746720941\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 895   90]\n",
            " [  65 1161]]\n"
          ]
        }
      ],
      "source": [
        "# Creating pipeline to prevent data leakage\n",
        "pipe_en = Pipeline([\n",
        "    ('scaler', StandardScaler()), # Scaling Data\n",
        "    ('model', LogisticRegression( # Logistic Regression\n",
        "        penalty='elasticnet',     # Elastic Net\n",
        "        solver='saga',            # Universal Solver for All 3 Types of Regression\n",
        "        max_iter=10000,           # Maximum number of iterations for solver to converge\n",
        "        random_state=1234         # Random State for Consistency\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Defining Parameters for Cross Validation\n",
        "en_cv_parameters = {\n",
        "    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9], # # Mix of L1 (lasso) and L2 (ridge) regularization\n",
        "    'model__C': [0.01, 0.1, 1, 10, 100] # C is the inverse regularization strength; smaller = stronger regularization\n",
        "}\n",
        "\n",
        "# Performing Cross Validation with GridSearchCV\n",
        "en = GridSearchCV(\n",
        "    estimator=pipe_en,\n",
        "    param_grid=en_cv_parameters,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fitting the Model\n",
        "en.fit(X_train, y_train)\n",
        "\n",
        "# Finding the Best Model\n",
        "best_en = en.best_estimator_\n",
        "\n",
        "# Predictions with the best performing model\n",
        "pred_train_en = best_en.predict(X_train)\n",
        "pred_test_en = best_en.predict(X_test)\n",
        "\n",
        "# Performance Metrics\n",
        "print(\"Best Hyperparameters:\", en.best_params_)\n",
        "print(\"Train Accuracy:\", accuracy_score(y_train, pred_train_en))\n",
        "print(\"Test Accuracy:\", accuracy_score(y_test, pred_test_en))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, pred_test_en))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dzrkNEEvPb9"
      },
      "source": [
        "**Best Model: Logistic Regression with L1 Lasson Regularization**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
